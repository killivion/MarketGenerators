{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(\"/dss/dsshome1/02/ge85rik2/MarketGenerators\")\n",
    "from src.evaluate import metrics as m\n",
    "from src.visualization.plot_option_results import OptionPricingVisualization \n",
    "from src.evaluate.option_pricing import OptionPricingEngine\n",
    "from src.data.make_dataset import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture all outputs of print functions\n",
    "from io import StringIO \n",
    "import sys\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio # free up some memory\n",
    "        sys.stdout = self._stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start evaluating all GBM-based models...\n",
      "numerical_results_Liao/GBM/mu=0.05_sigma=0.2/n-in=1000Y/seed=42/SigCWGAN\n",
      "No file found yet.\n",
      "numerical_results_Liao/GBM/mu=0.05_sigma=0.2/n-in=150Y/seed=42/TimeGAN\n",
      "   Evaluating model GBM/mu=0.05_sigma=0.2/n-in=150Y/seed=42...\n",
      "         Calculating option prices for TimeGAN paths\n",
      "numerical_results_Liao/GBM/mu=0.05_sigma=0.2/n-in=150Y/seed=42/CWGAN\n",
      "         Calculating option prices for CWGAN paths\n",
      "numerical_results_Liao/GBM/mu=0.05_sigma=0.2/n-in=150Y/seed=42/SigCWGAN\n",
      "         Calculating option prices for SigCWGAN paths\n",
      "numerical_results_Liao/GBM/mu=0.05_sigma=0.2/n-in=150Y/seed=42/RCGAN\n",
      "         Calculating option prices for RCGAN paths\n",
      "numerical_results_Liao/GBM/mu=0.05_sigma=0.2/n-in=150Y/seed=42/GMMN\n",
      "         Calculating option prices for GMMN paths\n",
      "numerical_results_Liao/GBM/mu=0.05_sigma=0.2/n-in=150Y/seed=42/RCWGAN\n",
      "         Calculating option prices for RCWGAN paths\n",
      "      Writing summary file at numerical_results_Liao/GBM/mu=0.05_sigma=0.2/n-in=150Y/seed=42.\n",
      "numerical_results_Liao/GBM/mu=0.05_sigma=0.2/n-in=10Y/seed=42/SigCWGAN\n",
      "No file found yet.\n",
      "Start evaluating all Kou_Jump_Diffusion-based models...\n",
      "numerical_results_Liao/Kou_Jump_Diffusion/mu=0.12_sigma=0.2_lambda=2.0_p=0.3_eta1=25.0_eta2=10.0/n-in=150Y/seed=42/TimeGAN\n",
      "   Evaluating model Kou_Jump_Diffusion/mu=0.12_sigma=0.2_lambda=2.0_p=0.3_eta1=25.0_eta2=10.0/n-in=150Y/seed=42...\n",
      "      ...Generating 1000000 paths of Kou_Jump_Diffusion model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-263e980095dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m314\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"      ...Generating {n_approx} paths of {input_model} model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                         \u001b[0mapprox_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                         \u001b[0mlast_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MarketGenerators/src/data/make_dataset.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, output_type)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Transform the data so that each time step is a row and each path is a column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np.ndarray\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MarketGenerators/src/data/make_dataset.py\u001b[0m in \u001b[0;36msimulate_kou_jump_diffusion\u001b[0;34m(self, S0, mu, sigma, lambda_, p, eta1, eta2, T, n_points, n)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;31m# iterate through number of jumps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;31m# vi contains all jumps that happen in one increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mvi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0;31m# loop over all jumps in one time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, order)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the base directory\n",
    "base_dir = \"numerical_results_Liao\"\n",
    "\n",
    "# Define the folders of interest\n",
    "model_folders = [\"GBM\", \"Kou_Jump_Diffusion\"]\n",
    "\n",
    "# Define the target subfolders\n",
    "target_subfolders = [\"CWGAN\", \"GMMN\", \"RCGAN\", \"RCWGAN\", \"SigCWGAN\", \"TimeGAN\"]\n",
    "freq = \"Y\"\n",
    "n_in = \"n-in=150\"+freq\n",
    "num_columns = 252\n",
    "\n",
    "# Parameters\n",
    "S0 = 1\n",
    "T = 1\n",
    "t = 0\n",
    "K_grid = np.linspace(0.8, 1.2, 100) if freq == \"M\" else np.linspace(0.5, 1.5, 100)\n",
    "# initialize epmty last specification\n",
    "last_spec=\"\"\n",
    "\n",
    "# Loop through each model folder\n",
    "for model_folder in model_folders:\n",
    "    print(f\"Start evaluating all {model_folder}-based models...\")\n",
    "    model_path = os.path.join(base_dir, model_folder)\n",
    "    \n",
    "    # Traverse the directory tree\n",
    "    for root, dirs, files in os.walk(model_path):\n",
    "        gen_model = os.path.basename(root)  \n",
    "        \n",
    "        if gen_model in target_subfolders:\n",
    "            # Read the relevant npy files\n",
    "            generated_file = os.path.join(root, \"generated_returns_rescaled.npy\")\n",
    "            input_file = os.path.join(root, \"input_returns_unscaled.npy\")\n",
    "            print(root)\n",
    "            if os.path.exists(generated_file) and os.path.exists(input_file):\n",
    "                input_returns = np.load(input_file).reshape((-1, num_columns))\n",
    "                input_prices_np = np.exp(np.cumsum(input_returns, axis=1))     \n",
    "                input_prices_df = pd.DataFrame(np.insert(input_prices_np, 0, 1, axis=1))\n",
    "                \n",
    "                #take the same number of output paths as the input paths\n",
    "                n_input_returns = np.prod(input_returns.shape)\n",
    "                generated_returns = np.load(generated_file).flatten()[:n_input_returns].reshape((-1, num_columns))\n",
    "                generated_prices_np = np.exp(np.cumsum(generated_returns, axis=1))               \n",
    "                generated_prices_df = pd.DataFrame(np.insert(generated_prices_np, 0, 1, axis=1))\n",
    "                \n",
    "                input_model = root.split(\"/\")[1] \n",
    "                model_spec = root.split(\"/\")[2]\n",
    "                # TimeGAN is first folder ==> New evaluation\n",
    "                if gen_model == \"TimeGAN\":\n",
    "                    closePlots = False\n",
    "                    # Reset output string\n",
    "                    summary_output = \"\"\n",
    "                    model_desc = \"/\".join(root.split(\"/\")[1:5])\n",
    "                    pairs = model_spec.split(\"_\")\n",
    "                    params = {key: float(value) for key, value in (pair.split(\"=\") for pair in pairs)}\n",
    "                    print(f\"   Evaluating model {model_desc}...\")\n",
    "\n",
    "                    if input_model != \"GBM\" and model_spec != last_spec:\n",
    "                        # create data for approximate exact price (100,000 paths) in the first run\n",
    "                        # fix lambda naming:\n",
    "                        if \"lambda\" in params:\n",
    "                            params[\"lambda_\"] = params.pop(\"lambda\")\n",
    "                        n_approx = 1000000\n",
    "                        params[\"n\"] = n_approx\n",
    "                        params[\"T\"] = T\n",
    "                        params[\"n_points\"] = num_columns+1\n",
    "                        params[\"S0\"] = S0\n",
    "                        dataloader = DataLoader(method=root.split(\"/\")[1], params=params, seed=314)\n",
    "                        print(f\"      ...Generating {n_approx} paths of {input_model} model...\")\n",
    "                        approx_df = dataloader.create_dataset(output_type=\"DataFrame\")\n",
    "                        last_spec = model_spec\n",
    "                    \n",
    "                    # initialize new european option pricing engine\n",
    "                    european_engine = OptionPricingEngine(\n",
    "                        type=\"European\", \n",
    "                        S0=S0, \n",
    "                        T=T, \n",
    "                        t=t, \n",
    "                        ground_paths_df=input_prices_df, \n",
    "                        gen_paths_df=generated_prices_df,\n",
    "                        approx_exact=(input_model != \"GBM\"),\n",
    "                    )\n",
    "                    \n",
    "                    \n",
    "                input_spec = \"-\".join(root.split(\"/\")[1:5]).replace(\".\", \",\")\n",
    "                \n",
    "                # Get respective path metrics\n",
    "                if input_model == \"GBM\":\n",
    "                    # To do: read the sigma and mu values dynamically (not important for now)\n",
    "                    approx_df = None\n",
    "                    european_engine.sigma = params[\"sigma\"]\n",
    "                    european_engine.r = params[\"mu\"]\n",
    "                    exact_label = \"Theoretical \"\n",
    "                    with Capturing(summary_output) as summary_output:\n",
    "                        print(gen_model + \" \" + input_spec)\n",
    "                        m.print_basic_gbm_metrics(\n",
    "                            n_periods = T, \n",
    "                            annualization_factor = 252, \n",
    "                            ground_paths_df = input_prices_df, \n",
    "                            recovered_paths_df = generated_prices_df, \n",
    "                            exp_stdev = european_engine.sigma,  \n",
    "                            mu = european_engine.r,  \n",
    "                            return_threshold = 0.03\n",
    "                        )\n",
    "                else:\n",
    "                    exact_label = \"Approximated \"\n",
    "                    with Capturing(summary_output) as summary_output:\n",
    "                        print(gen_model + \" \" + input_spec)\n",
    "                        european_engine.r = m.print_basic_non_gbm_metrics( \n",
    "                            n_periods=T,\n",
    "                            annualization_factor = 252, \n",
    "                            ground_paths_df = input_prices_df, \n",
    "                            recovered_paths_df = generated_prices_df, \n",
    "                            approx_df=approx_df,\n",
    "                            return_threshold = 0.03\n",
    "                        )\n",
    "                        \n",
    "            \n",
    "                print(f\"         Calculating option prices for {gen_model} paths\")\n",
    "                # calculate all values (option prices & deviations) for different strike prices (K values)\n",
    "                european_engine.gen_paths_df=generated_prices_df\n",
    "                european_engine.calc_all_K(K_grid, approx_df=approx_df, recalculate_all=False)\n",
    "                # Plot all types of plots\n",
    "                if gen_model == \"TimeGAN\":\n",
    "                    # initialize new plotter\n",
    "                    european_plotter = OptionPricingVisualization(european_engine, exact_label=exact_label, file_name=input_spec)\n",
    "                \n",
    "                # use new pricing engine for respective model\n",
    "                european_plotter.pe = european_engine\n",
    "                \n",
    "                # Save all results to files\n",
    "                if gen_model == \"RCWGAN\":\n",
    "                    # RCWGAN is last model and thus finishes the output\n",
    "                    # Specify file location\n",
    "                    relevant_dir = \"/\".join(root.split(\"/\")[:-1])\n",
    "                    print(f\"      Writing summary file at {relevant_dir}.\")\n",
    "                    with open(f\"{relevant_dir}/basic_metrics.txt\", \"w\") as text_file:\n",
    "                        text_file.write(\"\\n\".join(summary_output))\n",
    "                    closePlots = True\n",
    "                \n",
    "                # Plot option results\n",
    "                european_plotter.plot_option_prices(close=closePlots, label=gen_model)\n",
    "                european_plotter.plot_option_price_deviation(close=closePlots, label=gen_model)\n",
    "                european_plotter.plot_option_price_deviation_relative(close=closePlots, label=gen_model, zoom_ylimits=(0,50))\n",
    "            else:\n",
    "                print(\"No file found yet.\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
